{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elementos que contiene el Kit de Herramientas OpenVINO\n",
    "El Kit de Herramientas OpenVINO viene cargado de un montón de herramientas útiles para el desarrollo de aplicación de Inteligencia Artificial para dispositivos de frontera, dichas herramientas son compatibles con las otras herramientas de software de [Intel](https://software.intel.com/content/www/us/en/develop/home.html). Entre las más destacadas, tenemos: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizador de Modelos de Aprendizaje Profundo\n",
    "Es una aplicación de línea de comandos, compatible con varias plataformas para importar, convertir, preparar y optimizar modelos para ejecutarlos en el Motor de Inferencia de Intel. Es compatible con varios formatos populares de modelos de Deep Learning, como pueden ser: \n",
    "- Caffe\n",
    "- TensorFlow\n",
    "- MXNet\n",
    "- Kaldi\n",
    "- ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motor de Inferencia de Aprendizaje Profundo\n",
    "Corresponde a una API unificada, que permite desarrollar una inferencia de alto rendimiento en los dispositivos soportados por la Distribución de OpenVINO, únicamente puede ejecutar inferencia sobre modelos convertidos y compatibles con el motor de inferencia de INtel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Banco de Pruebas de Deep Learning\n",
    "Es un ambiente de pruebas basado en la web que permite el uso de varios componentes del ToolKit de OpenVINO de manera más fácil e intuitiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Herramienta de Optimización Post Entrenamiento\n",
    "Útil herramienta para calibrar un modelo y luego ejecutarlo en precisiones como la INT8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Model Zoo\n",
    "Importante fuente de datos de aprendizaje y desarrollo que provee Intel. Contiene una serie de ejemplos de aplicación, además de modelos pre-entrenados compatibles con el Motor de Inferencia de Intel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otras herramientas Interesantes\n",
    "- Herramienta de Benchmark: Útil para poder obtener métricas de la red\n",
    "- Cross Check Tool: Herramienta para comprarar la precisión y el rendimiento de dos sucesivos modelos que han sido optimizados\n",
    "- Compile tool: En el Lenguaje de Programación C++, sirve para compilar la inferencia por un modelo específico y exportarlo a un archivo binario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Referencia: https://docs.openvinotoolkit.org/latest/index.html#openvino_toolkit_components "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
