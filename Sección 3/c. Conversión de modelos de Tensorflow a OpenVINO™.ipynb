{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversión de modelos de Tensorflow a OpenVINO™\n",
    "\n",
    "**Ejemplo Práctico**\n",
    "\n",
    "## Pre-requisitos\n",
    "Como siempre, primero se debe activar las variables de entorno de OpenVINO, **ejecutando** la correspondiente celda de código.\n",
    "- *Windows*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.19043.1165]\r\n",
      "(c) Microsoft Corporation. All rights reserved.\r\n",
      "\r\n",
      "C:\\Users\\josej\\Documents\\Workshop-ESPEL-MCT-2021\\Secci¢n 3>\"C:\\Program Files (x86)\\Intel\\openvino_2021\\bin\\setupvars.bat\"\n",
      "Python 3.8.10\r\n",
      "[setupvars.bat] OpenVINO environment initialized\r\n",
      "\r\n",
      "C:\\Users\\josej\\Documents\\Workshop-ESPEL-MCT-2021\\Secci¢n 3>"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "\"C:\\Program Files (x86)\\Intel\\openvino_2021\\bin\\setupvars.bat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Linux*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source /opt/intel/openvino_2021/bin/setupvars.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descargar el archivo de Conversión\n",
    "El presente archivo de ejemplo corresponde a un modelo para Detección de Objetos ligero, que ha sido entrenado con el Dataset de COCO(90 clases de objetos). Será descargado para hacer la conversión de la siguiente página [http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz](http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz), para automatizar la descarga, se puede **ejecutar** esta celda de código \n",
    "- *Windows*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  0 19.5M    0 12702    0     0  12702      0  0:26:55 --:--:--  0:26:55 18068\r",
      "  1 19.5M    1  398k    0     0   398k      0  0:00:50  0:00:01  0:00:49  238k\r",
      "  3 19.5M    3  693k    0     0   346k      0  0:00:57  0:00:02  0:00:55  259k\r",
      "  5 19.5M    5 1058k    0     0   352k      0  0:00:56  0:00:03  0:00:53  288k\r",
      "  6 19.5M    6 1364k    0     0   341k      0  0:00:58  0:00:04  0:00:54  292k\r",
      "  8 19.5M    8 1692k    0     0   338k      0  0:00:59  0:00:05  0:00:54  337k\r",
      "  9 19.5M    9 1977k    0     0   329k      0  0:01:00  0:00:06  0:00:54  315k\r",
      " 11 19.5M   11 2382k    0     0   340k      0  0:00:58  0:00:07  0:00:51  337k\r",
      " 13 19.5M   13 2676k    0     0   334k      0  0:00:59  0:00:08  0:00:51  323k\r",
      " 14 19.5M   14 2982k    0     0   331k      0  0:01:00  0:00:09  0:00:51  323k\r",
      " 15 19.5M   15 3179k    0     0   317k      0  0:01:03  0:00:10  0:00:53  298k\r",
      " 16 19.5M   16 3317k    0     0   301k      0  0:01:06  0:00:11  0:00:55  268k\r",
      " 17 19.5M   17 3412k    0     0   284k      0  0:01:10  0:00:12  0:00:58  206k\r",
      " 17 19.5M   17 3468k    0     0   266k      0  0:01:15  0:00:13  0:01:02  158k\r",
      " 17 19.5M   17 3554k    0     0   253k      0  0:01:18  0:00:14  0:01:04  114k\r",
      " 18 19.5M   18 3759k    0     0   250k      0  0:01:19  0:00:15  0:01:04  116k\r",
      " 20 19.5M   20 4038k    0     0   252k      0  0:01:19  0:00:16  0:01:03  144k\r",
      " 21 19.5M   21 4295k    0     0   252k      0  0:01:19  0:00:17  0:01:02  176k\r",
      " 23 19.5M   23 4630k    0     0   257k      0  0:01:17  0:00:18  0:00:59  232k\r",
      " 24 19.5M   24 4931k    0     0   259k      0  0:01:17  0:00:19  0:00:58  275k\r",
      " 25 19.5M   25 5199k    0     0   259k      0  0:01:17  0:00:20  0:00:57  288k\r",
      " 27 19.5M   27 5540k    0     0   263k      0  0:01:15  0:00:21  0:00:54  300k\r",
      " 29 19.5M   29 5919k    0     0   269k      0  0:01:14  0:00:22  0:00:52  324k\r",
      " 31 19.5M   31 6294k    0     0   273k      0  0:01:13  0:00:23  0:00:50  332k\r",
      " 33 19.5M   33 6712k    0     0   279k      0  0:01:11  0:00:24  0:00:47  356k\r",
      " 35 19.5M   35 7110k    0     0   284k      0  0:01:10  0:00:25  0:00:45  382k\r",
      " 37 19.5M   37 7498k    0     0   288k      0  0:01:09  0:00:26  0:00:43  391k\r",
      " 39 19.5M   39 7882k    0     0   291k      0  0:01:08  0:00:27  0:00:41  392k\r",
      " 41 19.5M   41 8236k    0     0   294k      0  0:01:08  0:00:28  0:00:40  388k\r",
      " 42 19.5M   42 8603k    0     0   296k      0  0:01:07  0:00:29  0:00:38  378k\r",
      " 45 19.5M   45 9032k    0     0   301k      0  0:01:06  0:00:30  0:00:36  384k\r",
      " 47 19.5M   47 9422k    0     0   303k      0  0:01:05  0:00:31  0:00:34  384k\r",
      " 48 19.5M   48 9811k    0     0   306k      0  0:01:05  0:00:32  0:00:33  385k\r",
      " 50 19.5M   50  9.9M    0     0   308k      0  0:01:04  0:00:33  0:00:31  390k\r",
      " 52 19.5M   52 10.2M    0     0   309k      0  0:01:04  0:00:34  0:00:30  386k\r",
      " 54 19.5M   54 10.6M    0     0   310k      0  0:01:04  0:00:35  0:00:29  366k\r",
      " 55 19.5M   55 10.9M    0     0   311k      0  0:01:04  0:00:36  0:00:28  357k\r",
      " 58 19.5M   58 11.3M    0     0   314k      0  0:01:03  0:00:37  0:00:26  362k\r",
      " 59 19.5M   59 11.7M    0     0   316k      0  0:01:03  0:00:38  0:00:25  365k\r",
      " 61 19.5M   61 12.0M    0     0   317k      0  0:01:03  0:00:39  0:00:24  367k\r",
      " 64 19.5M   64 12.5M    0     0   320k      0  0:01:02  0:00:40  0:00:22  392k\r",
      " 65 19.5M   65 12.8M    0     0   321k      0  0:01:02  0:00:41  0:00:21  396k\r",
      " 67 19.5M   67 13.3M    0     0   324k      0  0:01:01  0:00:42  0:00:19  400k\r",
      " 69 19.5M   69 13.6M    0     0   325k      0  0:01:01  0:00:43  0:00:18  396k\r",
      " 71 19.5M   71 14.0M    0     0   327k      0  0:01:01  0:00:44  0:00:17  406k\r",
      " 74 19.5M   74 14.5M    0     0   331k      0  0:01:00  0:00:45  0:00:15  414k\r",
      " 75 19.5M   75 14.8M    0     0   330k      0  0:01:00  0:00:46  0:00:14  399k\r",
      " 77 19.5M   77 15.1M    0     0   330k      0  0:01:00  0:00:47  0:00:13  380k\r",
      " 79 19.5M   79 15.5M    0     0   331k      0  0:01:00  0:00:48  0:00:12  379k\r",
      " 81 19.5M   81 16.0M    0     0   334k      0  0:00:59  0:00:49  0:00:10  396k\r",
      " 83 19.5M   83 16.3M    0     0   334k      0  0:00:59  0:00:50  0:00:09  360k\r",
      " 85 19.5M   85 16.7M    0     0   337k      0  0:00:59  0:00:51  0:00:08  401k\r",
      " 87 19.5M   87 17.1M    0     0   337k      0  0:00:59  0:00:52  0:00:07  407k\r",
      " 90 19.5M   90 17.6M    0     0   340k      0  0:00:58  0:00:53  0:00:05  430k\r",
      " 91 19.5M   91 17.9M    0     0   339k      0  0:00:58  0:00:54  0:00:04  394k\r",
      " 94 19.5M   94 18.4M    0     0   342k      0  0:00:58  0:00:55  0:00:03  430k\r",
      " 95 19.5M   95 18.7M    0     0   342k      0  0:00:58  0:00:56  0:00:02  401k\r",
      " 98 19.5M   98 19.1M    0     0   344k      0  0:00:58  0:00:57  0:00:01  417k\r",
      " 99 19.5M   99 19.5M    0     0   345k      0  0:00:58  0:00:58 --:--:--  394k\r",
      "100 19.5M  100 19.5M    0     0   345k      0  0:00:58  0:00:58 --:--:--  416k\r\n",
      "Archivo Guardado en: C:\\Users\\josej\\Documents\\Workshop-ESPEL-MCT-2021\\Secci¢n 3 \r\n"
     ]
    }
   ],
   "source": [
    "%%cmd --out output\n",
    "SET descarga=http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\n",
    "curl -o ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz %descarga%\n",
    "echo Archivo Guardado en: %cd% >&2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Linux*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash --out output\n",
    "descarga=http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\n",
    "wget $descarga\n",
    "echo \"Archivo descargado en:\" pwd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descomprimir el archivo\n",
    "Es necesario descomprimir el archivo para poder obtener los datos necesarios para el procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo extraído en: C:\\Users\\josej\\Documents\\Workshop-ESPEL-MCT-2021\\Sección 3\\ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8\n"
     ]
    }
   ],
   "source": [
    "import tarfile, os\n",
    "directorio = os.getcwd()\n",
    "nombre_archivo = \"ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8\"\n",
    "extension = \".tar.gz\"\n",
    "ruta_archivo=os.path.join(directorio, \"{}{}\".format(nombre_archivo, extension))\n",
    "ruta_final_descomprimida=os.path.join(directorio, nombre_archivo)\n",
    "\n",
    "with tarfile.open(ruta_archivo, 'r') as tar_file:\n",
    "    tar_file.extractall(\"\") # Extraer en el mismo directorio\n",
    "    print(\"Archivo extraído en: {}\".format(ruta_final_descomprimida))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversión de TF v2 hacia la Representación Intermedia\n",
    "La carpeta descomprimida comprende de dos carpetas y un archivos,que son los siguientes:\n",
    "- checkpoint/ \n",
    "- saved_model/\n",
    "- pipeline.config \n",
    "\n",
    "En este específico ejemplo de Tensorflow v2, la carpeta *checkpoint/* contiene información sobre el entrenamiento y la carpeta *saved_model/* comprende una descripción serializada del modelo y  contiene el archivo final del entrenamiento en formato *.pb*, el archivo *pipeline.config* contiene información sobre la arquitectura del modelo y sobre las opciones de entrenamiento que se usó.\n",
    "\n",
    "El comando mínimo para la conversión de un modelo de Tensorflow V2 es el siguiente: \n",
    "```bash\n",
    "python3 mo_tf.py --saved_model_dir <SAVED_MODEL_DIRECTORY> --output_dir <OUTPUT_MODEL_DIR>\n",
    "```\n",
    "\n",
    "El argumento *SAVED_MODEL_DIRECTORY* se refiere a la ubicación de la carpeta de *saved_model* del modelo de descargado de TensorFlow v2. La variable *OUTPUT_MODEL_DIR* es un directorio donde deseemos guardar nuestro modelo convertido\n",
    "\n",
    "**Nota:** En caso de que se quiera usar el modelo con la librería OpenCV para adquisición de imágenes, es necesario colocar la opción *--reverse_input_channels* en los argumentos de la conversión. Puesto que en TF se utiliza la convención de canales de color *RGB* en cambio en OpenCV se usa el formato *BGR*. En este ejemplo se seguirá la convenvión *BGR*.\n",
    "\n",
    "Debido a que el modelo *ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8* es parte del proyecto TF Object Detection API(que simplifica las operaciones de entrenamiento y propuesta de arquitecturas de Deep Learning), es necesario definir las configuraciones de transformación `--transformations_config` para arquitecturas Single Shot Detectors de TF V2, en este caso el archivo está ubicado en la siguiente dirección `<INSTALL_DIR>/deployment_tools/model_optimizer/extensions/front/tf/ssd_support_api_v2.0.json\"`[2], en total el comando total a utilizar es el siguiente: \n",
    "```bash\n",
    "python3 mo.py --saved_model_dir <SAVED_MODEL_DIR> --tensorflow_object_detection_api_pipeline_config <PIPELINE_FILE> --transformations_config <MO_DIR>/deployment_tools/model_optimizer/extensions/tf/ssd_support_api_v2.0.json --output_dir <OUTPUT_DIR> --reverse_input_channels\n",
    "```\n",
    "\n",
    "La conversión se puede realizar **ejecutando** el siguiente script en este Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \tNone\n",
      "\t- Path for generated IR: \tC:\\Users\\josej\\Documents\\Workshop-ESPEL-MCT-2021\\Sección 3\\ssd_mobilenet_v2_fpnlite_640x640_OpenVINO\n",
      "\t- IR output name: \tsaved_model\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tNone\n",
      "\t- Reverse input channels: \tTrue\n",
      "TensorFlow specific parameters:\n",
      "\t- Input model in text protobuf format: \tFalse\n",
      "\t- Path to model dump for TensorBoard: \tNone\n",
      "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
      "\t- Update the configuration file with input/output node names: \tNone\n",
      "\t- Use configuration file used to generate the model with Object Detection API: \tC:\\Users\\josej\\Documents\\Workshop-ESPEL-MCT-2021\\Sección 3\\ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8\\pipeline.config\n",
      "\t- Use the config file: \tNone\n",
      "[ WARNING ] Failed to import Inference Engine Python API in: C:\\Program Files (x86)\\Intel\\openvino_2021.4.582\\python\\python3.8\n",
      "[ WARNING ] DLL load failed while importing ie_api: The specified module could not be found.\n",
      "[ WARNING ] Could not find the Inference Engine Python API. At this moment, the Inference Engine dependency is not required, but will be required in future releases.\n",
      "[ WARNING ] Consider building the Inference Engine Python API from sources or try to install OpenVINO (TM) Toolkit using \"install_prerequisites.sh\"\n",
      "Model Optimizer version: \t2021.4.0-3839-cd81789d294-releases/2021/4\n",
      "The Preprocessor block has been removed. Only nodes performing mean value subtraction and scaling (if applicable) are kept.\n",
      "[ SUCCESS ] Generated IR version 10 model.\n",
      "[ SUCCESS ] XML file: C:\\Users\\josej\\Documents\\Workshop-ESPEL-MCT-2021\\Sección 3\\ssd_mobilenet_v2_fpnlite_640x640_OpenVINO\\saved_model.xml\n",
      "[ SUCCESS ] BIN file: C:\\Users\\josej\\Documents\\Workshop-ESPEL-MCT-2021\\Sección 3\\ssd_mobilenet_v2_fpnlite_640x640_OpenVINO\\saved_model.bin\n",
      "[ SUCCESS ] Total execution time: 133.72 seconds. \n",
      "Archivo Guardado en: ssd_mobilenet_v2_fpnlite_640x640_OpenVINO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-08 23:14:16.518742: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2021-09-08 23:14:16.518768: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-09-08 23:14:21.102893: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-09-08 23:14:21.105766: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll\n",
      "2021-09-08 23:14:21.600082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 950M computeCapability: 5.0\n",
      "coreClock: 1.124GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 29.83GiB/s\n",
      "2021-09-08 23:14:21.601139: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2021-09-08 23:14:21.602054: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found\n",
      "2021-09-08 23:14:21.603020: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cublasLt64_11.dll'; dlerror: cublasLt64_11.dll not found\n",
      "2021-09-08 23:14:21.603933: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found\n",
      "2021-09-08 23:14:21.604913: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found\n",
      "2021-09-08 23:14:21.606398: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cusolver64_10.dll'; dlerror: cusolver64_10.dll not found\n",
      "2021-09-08 23:14:21.607621: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found\n",
      "2021-09-08 23:14:21.608836: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found\n",
      "2021-09-08 23:14:21.608856: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-09-08 23:14:21.609115: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-08 23:14:21.609749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-09-08 23:14:21.609765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n",
      "2021-09-08 23:14:21.609805: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-09-08 23:14:34.789300: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2021-09-08 23:14:34.789471: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
      "2021-09-08 23:14:34.793183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 950M computeCapability: 5.0\n",
      "coreClock: 1.124GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 29.83GiB/s\n",
      "2021-09-08 23:14:34.794347: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2021-09-08 23:14:34.796156: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found\n",
      "2021-09-08 23:14:34.797643: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cublasLt64_11.dll'; dlerror: cublasLt64_11.dll not found\n",
      "2021-09-08 23:14:34.798976: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found\n",
      "2021-09-08 23:14:34.799804: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found\n",
      "2021-09-08 23:14:34.800612: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cusolver64_10.dll'; dlerror: cusolver64_10.dll not found\n",
      "2021-09-08 23:14:34.801419: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found\n",
      "2021-09-08 23:14:34.802210: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found\n",
      "2021-09-08 23:14:34.802223: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-09-08 23:14:34.877852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-09-08 23:14:34.877875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-09-08 23:14:34.877887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-09-08 23:14:34.877901: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-09-08 23:14:35.670357: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:928] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: Graph size after: 9283 nodes (8874), 11504 edges (11088), time = 462.938ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 9.748ms.\n",
      "\n",
      "[ WARNING ]  Using fallback to produce IR.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "nombre_mo = \"mo.py\"\n",
    "nombre_modelo = \"ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8\"\n",
    "ruta_archivo_convertido = \"saved_model\"\n",
    "carpeta_salida_archivos = \"ssd_mobilenet_v2_fpnlite_640x640_OpenVINO\" #Cambiar esta ruta si se desea\n",
    "ruta_archivo_transformacion=\"extensions/front/tf/ssd_support_api_v2.0.json\"\n",
    "ruta_modelo_pipeline = os.path.join(nombre_modelo, \"pipeline.config\")\n",
    "if sys.platform == \"win32\":\n",
    "    ruta_mo = os.path.normpath(\"C:/Program Files (x86)/Intel/openvino_2021/deployment_tools/model_optimizer\")\n",
    "    transformaciones_config = os.path.join(ruta_mo, ruta_archivo_transformacion) #Ruta a las transformaciones de configuracion\n",
    "    ruta_model_optimizer = os.path.join(ruta_mo, nombre_mo) #Union de directorios \n",
    "    ruta_model_optimizer = '\"{}\"'.format(ruta_model_optimizer) #Conversion de Path a formato Windows\n",
    "    transformaciones_config = '\"{}\"'.format(os.path.normpath(transformaciones_config))\n",
    "    ruta_modelo_descargado_sd = os.path.join(nombre_modelo, ruta_archivo_convertido)\n",
    "    comando_total = ruta_model_optimizer + \" --saved_model_dir \" + ruta_modelo_descargado_sd \\\n",
    "    + \" --tensorflow_object_detection_api_pipeline_config \" + ruta_modelo_pipeline + \" --transformations_config \" \\\n",
    "    + transformaciones_config + \" --output_dir \" + carpeta_salida_archivos + \" --reverse_input_channels\"\n",
    "    !python {comando_total}\n",
    "    print(\"Archivo Guardado en: {}\".format(carpeta_salida_archivos))\n",
    "elif sys.platform == \"linux\":\n",
    "    ruta_mo = \"/opt/intel/openvino_2021/deployment_tools/model_optimizer/\"\n",
    "    transformaciones_config = os.path.join(ruta_mo, ruta_archivo_transformacion) #Ruta a las transformaciones de configuracion\n",
    "    ruta_model_optimizer = os.path.join(ruta_mo, nombre_mo) #Union de directorios \n",
    "    ruta_modelo_descargado_sd = os.path.join(nombre_modelo, ruta_archivo_convertido)\n",
    "    comando_total = ruta_model_optimizer + \" --saved_model_dir \" + ruta_modelo_descargado_sd \\\n",
    "    + \" --tensorflow_object_detection_api_pipeline_config \" + ruta_modelo_pipeline + \" --transformations_config \" \\\n",
    "    + transformaciones_config + \" --output_dir \" + carpeta_salida_archivos + \" --reverse_input_channels\"\n",
    "    !python {comando_total}\n",
    "    print(\"Archivo Guardado en: {}\".format(carpeta_salida_archivos)) \n",
    "else:\n",
    "    print(\"SO no soportado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Dependiendo de la velocidad de ejecución del computador, y si dispone de una tarjeta gráfica configurada con TF, se demorará en promedio *dos minutos* en realizar la conversión.\n",
    "\n",
    "Si la conversión ha sido exitosa, se mostrará un mensaje parecido al siguiente que mostrará la ruta de los archivos convertidos\n",
    "\n",
    "```bash\n",
    "[ SUCCESS ] Generated IR version 10 model.\n",
    "[ SUCCESS ] XML file: C:\\Users\\josej\\Documents\\Workshop-ESPEL-MCT-2021\\Sección 3\\ssd_mobilenet_v2_fpnlite_640x640_OpenVINO\\saved_model.xml\n",
    "[ SUCCESS ] BIN file: C:\\Users\\josej\\Documents\\Workshop-ESPEL-MCT-2021\\Sección 3\\ssd_mobilenet_v2_fpnlite_640x640_OpenVINO\\saved_model.bin\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "- [1] Intel. (2021, Agosto 31). Converting a TensorFlow* Model. Intel. [https://docs.openvinotoolkit.org/latest/openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_TensorFlow.html](https://docs.openvinotoolkit.org/latest/openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_TensorFlow.html)\n",
    "- [1] Intel. (2021, Agosto 31). Converting TensorFlow* Object Detection API Models. Intel. [https://docs.openvinotoolkit.org/latest/openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_Object_Detection_API_Models.html](https://docs.openvinotoolkit.org/latest/openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_Object_Detection_API_Models.html)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
