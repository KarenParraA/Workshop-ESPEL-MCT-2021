{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversión de un modelo de ONNX con OpenVINO™\n",
    "\n",
    "**Ejemplo Práctico**\n",
    "\n",
    "## Pre-requisitos\n",
    "Como siempre, primero se debe activar las variables de entorno de OpenVINO, **ejecutando** la correspondiente celda de código.\n",
    "- *Windows*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.19043.1165]\r\n",
      "(c) Microsoft Corporation. All rights reserved.\r\n",
      "\r\n",
      "C:\\Users\\josej\\Documents\\Workshop-ESPEL-MCT-2021\\Secci¢n 3>\"C:\\Program Files (x86)\\Intel\\openvino_2021\\bin\\setupvars.bat\"\n",
      "Python 3.8.10\r\n",
      "[setupvars.bat] OpenVINO environment initialized\r\n",
      "\r\n",
      "C:\\Users\\josej\\Documents\\Workshop-ESPEL-MCT-2021\\Secci¢n 3>"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "\"C:\\Program Files (x86)\\Intel\\openvino_2021\\bin\\setupvars.bat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Linux*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source /opt/intel/openvino_2021/bin/setupvars.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descargar el archivo de Conversión\n",
    "El presente archivo de ejemplo corresponde a un modelo para Detección de Objetos ligero, de arquitectura Single Shot Detector(SSD) [1] que ha sido entrenado para detectar 80 clases de objetos. Será descargado para hacer la conversión de la siguiente página [https://github.com/onnx/models/blob/master/vision/object_detection_segmentation/ssd/model/ssd-10.onnx](https://github.com/onnx/models/blob/master/vision/object_detection_segmentation/ssd/model/ssd-10.onnx), para automatizar la descarga, se puede **ejecutar** esta celda de código \n",
    "- *Windows*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:03 --:--:--     0\r",
      "100  125k    0  125k    0     0  42719      0 --:--:--  0:00:03 --:--:-- 33619\r\n",
      "Archivo Guardado en: C:\\Users\\josej\\Documents\\Workshop-ESPEL-MCT-2021\\Secci¢n 3 \r\n"
     ]
    }
   ],
   "source": [
    "%%cmd --out output\n",
    "SET descarga=https://github.com/onnx/models/blob/master/vision/object_detection_segmentation/ssd/model/ssd-10.onnx\n",
    "SET nombre_modelo=ssd-10.onnx\n",
    "curl -o %nombre_modelo% %descarga%\n",
    "echo Archivo Guardado en: %cd% >&2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Linux*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash --out output\n",
    "descarga=https://github.com/onnx/models/blob/master/vision/object_detection_segmentation/ssd/model/ssd-10.onnx\n",
    "wget $descarga\n",
    "echo \"Archivo descargado en:\" pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El archivo descargado está descomprimido y listo para la conversión a la Representación Intermedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversión de ONXX la Representación Intermedia\n",
    "El siguiente archivo ha sido descargado:\n",
    "- ssd-10.onnx\n",
    "\n",
    "El presente archivo *ssd-10.onnx* contiene tanto la información de los pesos, como de la arquitectura de la Red, este tipo de formato ONNX es un estándar usado por varias companías para distribuir sus modelos de Deep Learning.\n",
    "\n",
    "El comando mínimo para la conversión de un modelo de ONNX es el siguiente: \n",
    "```bash\n",
    "python3 mo.py --input_model <INPUT_MODEL>.onnx --output_dir <OUTPUT_MODEL_DIR>\n",
    "```\n",
    "\n",
    "El argumento *INPUT_MODEL.onnx* se refiere a la ruta del archivo en formato ONNX. La variable *OUTPUT_MODEL_DIR* es un directorio donde deseemos guardar nuestro modelo convertido\n",
    "\n",
    "```bash\n",
    "python3 mo.py --saved_model_dir <SAVED_MODEL_DIR> --tensorflow_object_detection_api_pipeline_config <PIPELINE_FILE> --transformations_config <MO_DIR>/deployment_tools/model_optimizer/extensions/tf/ssd_support_api_v2.0.json --output_dir <OUTPUT_DIR> --reverse_input_channels\n",
    "```\n",
    "\n",
    "La conversión se puede realizar **ejecutando** el siguiente script en este Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "Archivo Convertido Guardado en: ssd_mobilenet_v1_10_OpenVINO\n",
      "\t- Path to the Input Model: \tC:\\Users\\josej\\Documents\\Workshop-ESPEL-MCT-2021\\Sección 3\\ssd-10.onnx\n",
      "\t- Path for generated IR: \tC:\\Users\\josej\\Documents\\Workshop-ESPEL-MCT-2021\\Sección 3\\ssd_mobilenet_v1_10_OpenVINO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARNING ]  Using fallback to produce IR.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- IR output name: \tssd-10\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tNone\n",
      "\t- Reverse input channels: \tFalse\n",
      "ONNX specific parameters:\n",
      "[ WARNING ] Failed to import Inference Engine Python API in: C:\\Program Files (x86)\\Intel\\openvino_2021.4.582\\python\\python3.8\n",
      "[ WARNING ] DLL load failed while importing ie_api: The specified module could not be found.\n",
      "[ WARNING ] Could not find the Inference Engine Python API. At this moment, the Inference Engine dependency is not required, but will be required in future releases.\n",
      "[ WARNING ] Consider building the Inference Engine Python API from sources or try to install OpenVINO (TM) Toolkit using \"install_prerequisites.sh\"\n",
      "Model Optimizer version: \t2021.4.0-3839-cd81789d294-releases/2021/4\n",
      "[ SUCCESS ] Generated IR version 10 model.\n",
      "[ SUCCESS ] XML file: C:\\Users\\josej\\Documents\\Workshop-ESPEL-MCT-2021\\Sección 3\\ssd_mobilenet_v1_10_OpenVINO\\ssd-10.xml\n",
      "[ SUCCESS ] BIN file: C:\\Users\\josej\\Documents\\Workshop-ESPEL-MCT-2021\\Sección 3\\ssd_mobilenet_v1_10_OpenVINO\\ssd-10.bin\n",
      "[ SUCCESS ] Total execution time: 29.98 seconds. \n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "nombre_mo = \"mo.py\"\n",
    "ruta_modelo = \"\" #Cambiar s ise desea\n",
    "carpeta_salida_archivos = \"ssd_10_OpenVINO\" #Cambiar esta ruta si se desea\n",
    "nombre_archivo=\"ssd-10.onnx\"\n",
    "ruta_modelo_entrada = os.path.join(ruta_modelo, nombre_archivo)\n",
    "if sys.platform == \"win32\":\n",
    "    ruta_mo = os.path.normpath(\"C:/Program Files (x86)/Intel/openvino_2021/deployment_tools/model_optimizer\")\n",
    "    ruta_model_optimizer = os.path.join(ruta_mo, nombre_mo) #Union de directorios \n",
    "    ruta_model_optimizer = '\"{}\"'.format(ruta_model_optimizer) #Conversion de Path a formato Windows\n",
    "    comando_total = ruta_model_optimizer + \" --input_model \" + ruta_modelo_entrada \\\n",
    "    + \" --output_dir \" + carpeta_salida_archivos \n",
    "    !python {comando_total}\n",
    "    print(\"Archivo Convertido Guardado en: {}\".format(carpeta_salida_archivos))\n",
    "elif sys.platform == \"linux\":\n",
    "    ruta_mo = \"/opt/intel/openvino_2021/deployment_tools/model_optimizer/\"\n",
    "    ruta_model_optimizer = os.path.join(ruta_mo, nombre_mo) #Union de directorios \n",
    "    comando_total = ruta_model_optimizer + \" --input_model \" + ruta_modelo_entrada \\\n",
    "    + \" --output_dir \" + carpeta_salida_archivos \n",
    "    !python {comando_total}\n",
    "    print(\"Archivo Convertido Guardado en: {}\".format(carpeta_salida_archivos))\n",
    "else:\n",
    "    print(\"SO no soportado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Dependiendo de la velocidad de ejecución del computador, se puede demorarar en promedio *un minutos* en realizar la conversión.\n",
    "\n",
    "Si la conversión ha sido exitosa, se mostrará un mensaje parecido al siguiente que mostrará la ruta de los archivos convertidos\n",
    "\n",
    "```bash\n",
    "Model Optimizer version: \t2021.4.0-3839-cd81789d294-releases/2021/4\n",
    "[ SUCCESS ] Generated IR version 10 model.\n",
    "[ SUCCESS ] XML file: C:\\Users\\josej\\Documents\\Workshop-ESPEL-MCT-2021\\Sección 3\\ssd_mobilenet_v1_10_OpenVINO\\ssd-10.xml\n",
    "[ SUCCESS ] BIN file: C:\\Users\\josej\\Documents\\Workshop-ESPEL-MCT-2021\\Sección 3\\ssd_mobilenet_v1_10_OpenVINO\\ssd-10.bin\n",
    "[ SUCCESS ] Total execution time: 29.98 seconds.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "- [1] ONNX. (2021, Agosto 31). Single Stage Detector. ONNX. https://github.com/onnx/models/tree/master/vision/object_detection_segmentation/ssd](https://github.com/onnx/models/tree/master/vision/object_detection_segmentation/ssd)\n",
    "- [1] Intel. (2021, Agosto 31). Converting a ONNX* Model. Intel. [https://docs.openvinotoolkit.org/latest/openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_ONNX.html](https://docs.openvinotoolkit.org/latest/openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_ONNX.html)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
